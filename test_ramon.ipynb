{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name: str, event_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe from a \"Events export\"-file downloaded from kinexon.\n",
    "\n",
    "    For best results, select all periods and only the metrics \"Timestamp in local format\" and desired event_type.\n",
    "\n",
    "    :param file_name: path to the file\n",
    "    :param event_type: event type, e.g. \"Shifts\", \"Changes of Direction\", ...\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        # read first line\n",
    "        columns = f.readline()\n",
    "\n",
    "        # get rid of weird starting characters and remove new line\n",
    "        columns = columns.strip()\n",
    "\n",
    "        # find descriptor of element type\n",
    "        event_columns = None\n",
    "        while True:\n",
    "            next_line = f.readline()\n",
    "\n",
    "            # all event-descriptors start with ;;;;. If it does not start with this, then its data\n",
    "            if not next_line.startswith(\";;;;\"):\n",
    "                break\n",
    "\n",
    "            # we find event type-descriptor\n",
    "            if event_type in next_line:\n",
    "                event_columns = next_line\n",
    "\n",
    "        if not event_columns:\n",
    "            raise ValueError(f\"CSV does not have a descriptor for {event_type}\")\n",
    "\n",
    "        # delete delete prefix and descriptor, i.e. \";;;;Shifts;\"\n",
    "        event_columns = event_columns[4 + len(event_type):]\n",
    "\n",
    "        # concat columns\n",
    "        columns += event_columns\n",
    "\n",
    "        # read all rows\n",
    "        file_str = columns\n",
    "        while next_line:\n",
    "            file_str += next_line\n",
    "            next_line = f.readline()\n",
    "\n",
    "        # replace comma separated first columns with semicolon\n",
    "        file_str = file_str.replace(\", \", \";\")\n",
    "\n",
    "        # save data to df\n",
    "        df = pd.read_csv(StringIO(file_str), sep=\";\", index_col=False)\n",
    "\n",
    "    df = df[df[\"Event type\"].str.contains(event_type[:-1])]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnol\\AppData\\Local\\Temp\\ipykernel_33444\\968578666.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from matplotlib.pyplot import text\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "BLOCK_CONFIG_NOF_SHIFTS_DESCRIPTOR = \"naive_number_of_shifts\"\n",
    "BLOCK_CONFIG_VERBOSE_DESCRIPTOR = \"verbose\"\n",
    "BLOCK_CONFIG_TEAM_NAME_DESCRIPTOR = \"team_name\"\n",
    "BLOCK_CONFIG_CSV_FILE_DESCRIPTOR = \"CSV_FILE\"\n",
    "BLOCK_CONFIG_SAVE_PLOT_DESCRIPTOR = \"PNG_FILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sis_column(df, players):\n",
    "    \"\"\"\n",
    "    Adds a 'SIS' (Shift Intensity Score) column to the DataFrame for guest players excluding goalkeepers.\n",
    "    This function filters the DataFrame for guest players, calculates the optimal number of shifts using KMeans clustering,\n",
    "    computes the average shift intensity, and calculates the SIS for each player based on the average intensity\n",
    "    of all their shifts relative to the overall average shift intensity of all players.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing player data including columns for 'Name', 'Timestamp (ms)', 'Duration (s)', and 'Skating Intensity'.\n",
    "    - player: list of strings containing the Player ID of the selected players to calculate SIS for.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The original DataFrame with an added 'SIS' column for each player.\n",
    "    \"\"\"\n",
    "    # Filter DataFrame for parameter players\n",
    "    df_filtered = df[df[\"Name\"].isin(players)].copy()\n",
    "\n",
    "    # Finding the optimal number of shifts\n",
    "    optimal_shifts, shift_labels = find_optimal_amount_of_shifts(df_filtered, True, False)\n",
    "\n",
    "    # Preparing data for clustering\n",
    "    data_for_clustering = df_filtered[[\"Timestamp (ms)\", \"Duration (s)\"]]\n",
    "\n",
    "    # Clustering with KMeans\n",
    "    kmeans = KMeans(n_clusters=optimal_shifts)\n",
    "    kmeans.fit(data_for_clustering)\n",
    "\n",
    "    # Adding cluster labels\n",
    "    df_filtered[\"Shift_Label\"] = kmeans.labels_\n",
    "\n",
    "    # Calculating average intensity for each shift\n",
    "    df_filtered['Average_Shift_Intensity'] = df_filtered.groupby('Shift_Label')['Skating Intensity'].transform('mean')\n",
    "\n",
    "    # Average intensity of all shifts for each player\n",
    "    player_shift_means = df_filtered.groupby(['Name', 'Shift_Label'])['Skating Intensity'].mean().reset_index()\n",
    "    player_average_intensity = player_shift_means.groupby('Name')['Skating Intensity'].mean()\n",
    "\n",
    "    # Average value of intensities for all shifts of all players\n",
    "    overall_average_shift_intensity = player_shift_means['Skating Intensity'].mean()\n",
    "\n",
    "    # Calculating SIS for each player\n",
    "    player_sis = player_average_intensity / overall_average_shift_intensity\n",
    "\n",
    "    # Adding the SIS to df_filtered\n",
    "    df_filtered['SIS'] = df_filtered['Name'].map(player_sis)\n",
    "\n",
    "    # order the shifts\n",
    "    df_filtered = utils.order_block_labels(df_filtered)\n",
    "\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of strings containing the Player ID of the selected players for Team \"TEST\"\n",
    "players = [\"438\", \"443\", \"448\", \"447\", \"456\", \"449\", \"460\", \"444\", \"439\", \"451\", \"453\", \"450\", \"445\", \"454\", \"441\", \"455\", \"452\", \"457\", \"446\", \"442\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m add_sis_column(\u001b[43mdf\u001b[49m, players)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "add_sis_column(df, players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
